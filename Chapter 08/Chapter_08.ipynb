{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e448a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refer to the following code for Image Segmentation in OpenCV.\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('image.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to obtain a binary image\n",
    "ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "# Morphological opening to remove noise\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# Background area using dilate\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "# Marker labelling\n",
    "_, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Adding one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Marking the region of unknown with zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "# Applying watershed algorithm\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Segmented Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910558d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code snippet that demonstrates how to perform face detection using Haar Cascade classifiers in OpenCV:\n",
    "\n",
    "# Note: keep the haarcascade.xml and input image file in the same folder where the code file exists.\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread('smile.jpg')\n",
    "\n",
    "# Convert the image to grayscale for face detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the grayscale image using the Haar Cascade classifier\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Draw rectangles around the detected faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the output image with detected faces\n",
    "cv2.imshow('Face Detection', img)\n",
    "\n",
    "# Wait for a key press and then exit\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a745c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code snippet that demonstrates how to perform face detection using Haar Cascade classifiers in OpenCV for an input video:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Create a video capture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image using the Haar Cascade classifier\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \"\"\" \n",
    "    scaleFactor: This parameter compensates for the fact that faces can appear at different sizes in an image. \n",
    "    It specifies how much the image size is reduced at each image scale. \n",
    "    A smaller value will increase the detection time but can lead to better detection, while a larger value will decrease the detection time but may miss smaller smiles. \n",
    "    The default value is 1.3, but in this case, it has been set to 2.1. \n",
    "\n",
    "    minNeighbors: This parameter controls the sensitivity of the detector. \n",
    "    It specifies how many neighbors a candidate smile rectangle should have to be retained. \n",
    "    Higher values will result in fewer detections but with higher confidence, and lower values will result in more detections but with lower confidence. \n",
    "    The default value is 3, but in this case, it has been set to 12\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Detection', frame)\n",
    "\n",
    "    # Check for user input to exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): break\n",
    "\n",
    "\n",
    "# Release the video capture object and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform eye detection using Haar Cascade classifiers in OpenCV for an input image:\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier for eye detection\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread('input.jpg')\n",
    "\n",
    "# Convert the image to grayscale for eye detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect eyes in the grayscale image using the Haar Cascade classifier\n",
    "eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "# Draw rectangles around the detected eyes\n",
    "for (x, y, w, h) in eyes:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "# Display the output image with detected eyes\n",
    "cv2.imshow('Eye Detection', img)\n",
    "\n",
    "# Wait for a key press and then exit\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cc2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform eye detection using Haar Cascade classifiers in OpenCV for an input video:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier for eye detection\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "# Load the input video file\n",
    "cap = cv2.VideoCapture('input.mp4')\n",
    "\n",
    "# Loop through the frames in the input video\n",
    "while True:\n",
    "    # Read a frame from the input video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Stop the loop if the end of the video is reached\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for eye detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect eyes in the grayscale image using the Haar Cascade classifier\n",
    "    eyes = eye_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "    # Draw rectangles around the detected eyes\n",
    "    for (x, y, w, h) in eyes:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the output video frame with detected eyes\n",
    "    cv2.imshow('Eye Detection', frame)\n",
    "\n",
    "    # Exit on ESC key\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495bebdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform smile detection using Haar Cascade classifiers in OpenCV for an input image:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the Haar Cascade classifier for smile detection\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "\n",
    "# Load the input image\n",
    "img = cv2.imread('smile.jpg')\n",
    "\n",
    "# Convert the image to grayscale for smile detection\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect smiles in the grayscale image using the Haar Cascade classifier\n",
    "smiles = smile_cascade.detectMultiScale(gray, scaleFactor=2.1, minNeighbors=12)\n",
    "\n",
    "\n",
    "\n",
    "# Draw rectangles around the detected smiles\n",
    "for (x, y, w, h) in smiles:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "# Display the output image with detected smiles\n",
    "cv2.imshow('Smile Detection', img)\n",
    "\n",
    "# Wait for a key press and then exit\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffa150",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform smile detection using Haar Cascade classifiers in OpenCV for an input video:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the pre-trained Haar Cascade classifier for face and smile detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "\n",
    "# Open the video capture device (0 is usually the built-in camera)\n",
    "cap = cv2.VideoCapture(\"baby.mp4\")\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture device\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Stop the loop if the end of the video is reached\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale for face and smile detection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=8, minSize=(30, 30))\n",
    "\n",
    "    # For each detected face, detect smiles\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "        # Region of Interest (ROI) for the detected face\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "        # Detect smiles in the ROI\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.7, minNeighbors=15, minSize=(25, 25))\n",
    "\n",
    "        # For each detected smile, draw a rectangle\n",
    "        for (sx, sy, sw, sh) in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx + sw, sy + sh), (0, 0, 255), 2)\n",
    "            \n",
    "    frame = cv2.resize(frame, (512, 512))\n",
    "\n",
    "    # Display the resulting image with detected faces and smiles\n",
    "    cv2.imshow('Smile Detection', frame)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture device and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2763868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform QR code detection using OpenCV for an input image:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# QR detector\n",
    "qcd = cv2.QRCodeDetector()\n",
    "\n",
    "# read the image\n",
    "\n",
    "frame = cv2.imread('QR.png')\n",
    "\n",
    "\n",
    "ret_qr, decoded_info, points, _ = qcd.detectAndDecodeMulti(frame)\n",
    "if ret_qr:\n",
    "    for s, p in zip(decoded_info, points):\n",
    "    \"\"\"\n",
    "    s = decoded_info: This is a list of decoded QR codes and their corresponding information. \n",
    "    p = points: This is a list of lists, where each sublist contains four (x, y) coordinates that represent the corners of a detected QR code in the image.\n",
    "    \"\"\"\n",
    "        if s:\n",
    "            print(s)\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "            \n",
    "        # Put the date and time on the frame\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(frame, s, (2, 15), font, .5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        frame = cv2.polylines(frame, [p.astype(int)], True, color, 8)\n",
    "cv2.imshow(\"QR code\", frame)\n",
    "\n",
    "#close the function\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform QR code detection using OpenCV for an input video:\n",
    "\n",
    "import cv2\n",
    "\n",
    "delay = 1\n",
    "window_name = 'OpenCV QR Code'\n",
    "\n",
    "qcd = cv2.QRCodeDetector()\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        ret_qr, decoded_info, points, _ = qcd.detectAndDecodeMulti(frame)\n",
    "        if ret_qr:\n",
    "            for s, p in zip(decoded_info, points):\n",
    "                if s:\n",
    "                    print(s)\n",
    "                    color = (0, 255, 0)\n",
    "                else:\n",
    "                    color = (0, 0, 255)\n",
    "                frame = cv2.polylines(frame, [p.astype(int)], True, color, 8)\n",
    "        cv2.imshow(window_name, frame)\n",
    "        \n",
    "    else: break\n",
    "    # Exit on the Q key        \n",
    "    if cv2.waitKey(delay) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code using images for OCR (Optical Character Recognition).\n",
    "# Note: You'll need to install pytesseract and the Tesseract OCR engine for this code to work.\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe' \n",
    "\n",
    "# read image using OpenCV\n",
    "img = cv2.imread('invoice.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# perform OCR using pytesseract\n",
    "print(pytesseract.image_to_string(img))\n",
    "\n",
    "# Detecting Characters\n",
    "hImg, wImg,_ = img.shape\n",
    "boxes = pytesseract.image_to_boxes(img)\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x,hImg- y), (w,hImg- h), (50, 50, 255), 2)\n",
    "    #cv2.putText(img,b[0],(x,hImg- y+25),cv2.FONT_HERSHEY_SIMPLEX,1,(50,50,255),2)\n",
    "\n",
    "img = cv2.resize(img, (640, 480))\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5047de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code using images for OCR (Optical Character Recognition).\n",
    "# Note: You'll need to install pytesseract and the Tesseract OCR engine for this code to work.\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Program Files/Tesseract-OCR/tesseract.exe' \n",
    "\n",
    "# read image using OpenCV\n",
    "img = cv2.imread('invoice.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# perform OCR using pytesseract\n",
    "print(pytesseract.image_to_string(img))\n",
    "\n",
    "# Detecting Characters\n",
    "hImg, wImg,_ = img.shape\n",
    "boxes = pytesseract.image_to_boxes(img)\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    x, y, w, h = int(b[1]), int(b[2]), int(b[3]), int(b[4])\n",
    "    cv2.rectangle(img, (x,hImg- y), (w,hImg- h), (50, 50, 255), 2)\n",
    "    #cv2.putText(img,b[0],(x,hImg- y+25),cv2.FONT_HERSHEY_SIMPLEX,1,(50,50,255),2)\n",
    "\n",
    "img = cv2.resize(img, (640, 480))\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c296392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa19e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2081cd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cb7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37575c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f8d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
