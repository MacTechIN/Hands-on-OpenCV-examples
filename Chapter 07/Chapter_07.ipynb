{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d820b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform object detection using HSV in OpenCV:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the callback function for the trackbar\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a named window for the trackbars\n",
    "cv2.namedWindow('Trackbars')\n",
    "\n",
    "# Create trackbars for Hue, Saturation, and Value\n",
    "cv2.createTrackbar('Hue_Low', 'Trackbars', 0, 179, nothing)\n",
    "cv2.createTrackbar('Hue_High', 'Trackbars', 179, 179, nothing)\n",
    "cv2.createTrackbar('Saturation_Low', 'Trackbars', 0, 255, nothing)\n",
    "cv2.createTrackbar('Saturation_High', 'Trackbars', 255, 255, nothing)\n",
    "cv2.createTrackbar('Value_Low', 'Trackbars', 0, 255, nothing)\n",
    "cv2.createTrackbar('Value_High', 'Trackbars', 255, 255, nothing)\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread('smarties.png')\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "while True:\n",
    "    # Get the current trackbar positions\n",
    "    h_low = cv2.getTrackbarPos('Hue_Low', 'Trackbars')\n",
    "    h_high = cv2.getTrackbarPos('Hue_High', 'Trackbars')\n",
    "    s_low = cv2.getTrackbarPos('Saturation_Low', 'Trackbars')\n",
    "    s_high = cv2.getTrackbarPos('Saturation_High', 'Trackbars')\n",
    "    v_low = cv2.getTrackbarPos('Value_Low', 'Trackbars')\n",
    "    v_high = cv2.getTrackbarPos('Value_High', 'Trackbars')\n",
    "\n",
    "    # Define the lower and upper bounds of the color to detect\n",
    "    lower_bound = np.array([h_low, s_low, v_low])\n",
    "    upper_bound = np.array([h_high, s_high, v_high])\n",
    "\n",
    "    # Create a mask using the lower and upper bounds\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # Show the original image and the result\n",
    "    cv2.imshow('Original', img)\n",
    "    cv2.imshow('Result', result)\n",
    "\n",
    "    # Wait for the user to press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fd46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform object tracking using HSV in OpenCV:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Load the video file\n",
    "cap = cv2.VideoCapture('dog.mp4')\n",
    "\n",
    "# Create a window and trackbars to adjust the color thresholds\n",
    "cv2.namedWindow('Object Detection')\n",
    "cv2.createTrackbar('Low H', 'Object Detection', 0, 179, nothing)\n",
    "cv2.createTrackbar('High H', 'Object Detection', 179, 179, nothing)\n",
    "cv2.createTrackbar('Low S', 'Object Detection', 0, 255, nothing)\n",
    "cv2.createTrackbar('High S', 'Object Detection', 255, 255, nothing)\n",
    "cv2.createTrackbar('Low V', 'Object Detection', 0, 255, nothing)\n",
    "cv2.createTrackbar('High V', 'Object Detection', 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    # Read the video frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Get the color thresholds from the trackbars\n",
    "    low_h = cv2.getTrackbarPos('Low H', 'Object Detection')\n",
    "    high_h = cv2.getTrackbarPos('High H', 'Object Detection')\n",
    "    low_s = cv2.getTrackbarPos('Low S', 'Object Detection')\n",
    "    high_s = cv2.getTrackbarPos('High S', 'Object Detection')\n",
    "    low_v = cv2.getTrackbarPos('Low V', 'Object Detection')\n",
    "    high_v = cv2.getTrackbarPos('High V', 'Object Detection')\n",
    "\n",
    "    # Define the color thresholds\n",
    "    lower_color = np.array([low_h, low_s, low_v])\n",
    "    upper_color = np.array([high_h, high_s, high_v])\n",
    "\n",
    "    # Threshold the HSV image to get only the object in the color range\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "\n",
    "    # Apply morphological operations to remove noise\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.erode(mask, kernel)\n",
    "    mask = cv2.dilate(mask, kernel)\n",
    "\n",
    "    # Find contours of the object in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw the contours on the original frame\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 100:\n",
    "            cv2.drawContours(frame, contour, -1, (0, 255, 0), 3)\n",
    "\n",
    "    # Display the frames\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "    cv2.imshow('Mask', mask)\n",
    "\n",
    "    # Press 'q' to exit the program\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac562ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean Shift algorithm for object tracking in OpenCV:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the input video file\n",
    "cap = cv2.VideoCapture('dog.mp4')\n",
    "\n",
    "# Read the first frame from the input video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Define the initial window location\n",
    "x, y, w, h = 300, 200, 100, 100\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# Extract the region of interest (ROI) from the first frame\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# Convert the ROI to the HSV color space\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Compute the histogram of the HSV color distribution in the ROI\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "\n",
    "# Normalize the histogram\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Define the termination criteria for the Mean Shift algorithm\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "# Loop through the frames in the input video\n",
    "while True:\n",
    "    # Read a frame from the input video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Stop the loop if the end of the video is reached\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the back projection of the histogram onto the frame\n",
    "    dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "    # Apply the Mean Shift algorithm to the back projection\n",
    "    ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "    # Draw a rectangle around the tracked object\n",
    "    x, y, w, h = track_window\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output video frame with the rectangle\n",
    "    cv2.imshow('Mean Shift Object Tracking', frame)\n",
    "\n",
    "    # Exit on ESC key\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e180da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CAMShift algorithm for object tracking in OpenCV:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the input video file\n",
    "cap = cv2.VideoCapture('dog.mp4')\n",
    "\n",
    "# Read the first frame from the input video\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Define the initial window location\n",
    "x, y, w, h = 300, 200, 100, 100\n",
    "track_window = (x, y, w, h)\n",
    "\n",
    "# Extract the region of interest (ROI) from the first frame\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# Convert the ROI to the HSV color space\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Compute the histogram of the HSV color distribution in the ROI\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0, 180])\n",
    "\n",
    "# Normalize the histogram\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "# Define the termination criteria for the CAMShift algorithm\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "# Loop through the frames in the input video\n",
    "while True:\n",
    "    # Read a frame from the input video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Stop the loop if the end of the video is reached\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to the HSV color space\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Calculate the back projection of the histogram onto the frame\n",
    "    dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "    # Apply the CAMShift algorithm to the back projection\n",
    "    ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "\n",
    "    # Draw an ellipse around the tracked object\n",
    "    pts = cv2.boxPoints(ret)\n",
    "    pts = np.int0(pts)\n",
    "    cv2.polylines(frame, [pts], True, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the output video frame with the ellipse\n",
    "    cv2.imshow('CAMShift Object Tracking', frame)\n",
    "\n",
    "    # Exit on ESC key\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### detecting markers with images using augmented reality (AR) in OpenCV.\n",
    "# Note: Download  ArUco Markers images for the following exercise. \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the dictionary and create the detector parameters\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "# Load the image \n",
    "img = cv2.imread(\"aruco_marker.png\")\n",
    "\n",
    "# Convert the frame to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect the markers in the frame\n",
    "corners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "\n",
    "# Draw the detected markers and their IDs on the frame\n",
    "if len(corners) > 0:\n",
    "    ids = ids.flatten()\n",
    "    for i, corner in enumerate(corners):\n",
    "        cv2.aruco.drawDetectedMarkers(img, corners, ids)\n",
    "\n",
    "# Show the frame\n",
    "img = cv2.resize(img, (1600, 1200))\n",
    "cv2.imshow('frame', img)\n",
    "\n",
    "\n",
    "#close the function\n",
    "cv2.waitKey(0)\n",
    "# lose all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "### detecting markers with videos using augmented reality (AR) in OpenCV.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the dictionary and create the detector parameters\n",
    "dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "parameters = cv2.aruco.DetectorParameters()\n",
    "detector = cv2.aruco.ArucoDetector(dictionary, parameters)\n",
    "\n",
    "# Start the camera capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read the current frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect the markers in the frame\n",
    "    corners, ids, rejectedImgPoints = detector.detectMarkers(gray)\n",
    "\n",
    "    # Draw the detected markers and their IDs on the frame\n",
    "    if len(corners) > 0:\n",
    "        ids = ids.flatten()\n",
    "        for i, corner in enumerate(corners):\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners, ids)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eaf65e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c584ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9ab39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c82648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dae0747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
