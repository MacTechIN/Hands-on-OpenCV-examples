{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7986d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### simple thresholding technique using OpenCV in Python:\n",
    "import cv2\n",
    "\n",
    "# Load the image in grayscale mode\n",
    "img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply simple thresholding\n",
    "threshold_value = 127\n",
    "max_value = 255\n",
    "ret, thresh = cv2.threshold(img, threshold_value, max_value, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display the original and thresholded images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Thresholded Image', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### adaptive thresholding technique using OpenCV in Python:\n",
    "import cv2\n",
    "\n",
    "# Load the image in grayscale mode\n",
    "img = cv2.imread('image.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply adaptive thresholding\n",
    "max_value = 255\n",
    "adaptive_method = cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "threshold_type = cv2.THRESH_BINARY_INV\n",
    "block_size = 11\n",
    "c = 2\n",
    "thresh = cv2.adaptiveThreshold(img, max_value, adaptive_method, threshold_type, block_size, c)\n",
    "\n",
    "\n",
    "# Display the original and thresholded images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Adaptive Thresholded Image', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Otsu's thresholding technique using OpenCV in Python:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# read image in grayscale\n",
    "img = cv2.imread('image.jpg', 0)\n",
    "\n",
    "# apply Otsu's thresholding\n",
    "ret, th = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# display original and thresholded images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Thresholded Image', th)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44de6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code for binary thresholding using OpenCV in Python.\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('image.jpg', 0)\n",
    "\n",
    "# Apply binary thresholding\n",
    "thresh_val, thresh = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Display the original and thresholded image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Thresholded Image', thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78a7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inverted thresholding using OpenCV in Python:\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('image.jpg', 0)\n",
    "\n",
    "# Apply thresholding\n",
    "thresh_val, thresh = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Show the original and thresholded images\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Thresholded Image', thresh)\n",
    "\n",
    "# Wait for key press and then close all windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dc1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code snippet to find and draw contours using OpenCV:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('image.jpg')\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply threshold to the image\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours in the image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on the image\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Display the image with contours\n",
    "cv2.imshow('Image with Contours', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb104a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### code to find and draw contours in a video using OpenCV:\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load video\n",
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "while True:\n",
    "    # Read frame from the video\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        # Convert frame to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply threshold to the frame\n",
    "        _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find contours in the frame\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Draw contours on the frame\n",
    "        cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with contours\n",
    "        cv2.imshow('Frame with Contours', frame)\n",
    "\n",
    "        # Press 'q' to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release video capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39513de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### detect simple geometric shapes such as circles, triangles, and squares in an image.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image and convert to grayscale\n",
    "image = cv2.imread(\"shapes.jpg\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection to detect edges in the image\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Find contours in the edge image\n",
    "contours, hierarchy = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Loop through each contour and check if it matches a circle, triangle, or square\n",
    "for cnt in contours:\n",
    "    # Calculate the perimeter of the contour\n",
    "    perimeter = cv2.arcLength(cnt, True)\n",
    "    \n",
    "    # Approximate the shape of the contour\n",
    "    approx = cv2.approxPolyDP(cnt, 0.04 * perimeter, True)\n",
    "    \n",
    "    # Calculate the number of vertices of the approximated shape\n",
    "    num_vertices = len(approx)\n",
    "    \n",
    "    # If the shape has 3 vertices, it's a triangle\n",
    "    if num_vertices == 3:\n",
    "        cv2.drawContours(image, [approx], 0, (0, 255, 0), 2)\n",
    "        cv2.putText(image, \"Triangle\", tuple(approx[0][0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    # If the shape has 4 vertices, it could be a square or a rectangle\n",
    "    elif num_vertices == 4:\n",
    "        # Calculate the aspect ratio of the shape\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        aspect_ratio = float(w) / h\n",
    "        \n",
    "        # If the aspect ratio is close to 1, it's a square\n",
    "        if 0.95 <= aspect_ratio <= 1.05:\n",
    "            cv2.drawContours(image, [approx], 0, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"Square\", tuple(approx[0][0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        # Otherwise, it's a rectangle\n",
    "        else:\n",
    "            cv2.drawContours(image, [approx], 0, (0, 255, 255), 2)\n",
    "            cv2.putText(image, \"Rectangle\", tuple(approx[0][0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "    # If the shape has more than 4 vertices, it's a circle\n",
    "    else:\n",
    "        cv2.drawContours(image, [approx], 0, (255, 0, 0), 2)\n",
    "        cv2.putText(image, \"Circle\", tuple(approx[0][0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "# Display the image with the detected shapes\n",
    "cv2.imshow(\"Shapes\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### example OpenCV code to understand image histograms:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Load an image in grayscale\n",
    "image = cv2.imread(\"lena.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Calculate the histogram of the image\n",
    "hist = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "\n",
    "# Plot the histogram using matplotlib\n",
    "plt.plot(hist)\n",
    "plt.xlim([0, 256])\n",
    "plt.show()\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b7a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refer to the following code for displaying Template matching using OpenCV\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the main image and the template image\n",
    "main_image = cv2.imread(\"dog.jpg\")\n",
    "template_image = cv2.imread(\"dog-head.jpg\")\n",
    "\n",
    "# Get the dimensions of the template image\n",
    "template_height, template_width, _ = template_image.shape\n",
    "\n",
    "# Apply template matching using the TM_CCOEFF_NORMED method\n",
    "result = cv2.matchTemplate(main_image, template_image, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "# Set a threshold to filter out weak matches\n",
    "threshold = 0.8\n",
    "locations = np.where(result >= threshold)\n",
    "locations = list(zip(*locations[::-1]))\n",
    "\n",
    "# Draw rectangles around the matching regions\n",
    "for loc in locations:\n",
    "    top_left = loc\n",
    "    bottom_right = (top_left[0] + template_width, top_left[1] + template_height)\n",
    "    cv2.rectangle(main_image, top_left, bottom_right, (0, 0, 255), 1)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow(\"Result\", main_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf62d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refer to the following code for displaying Template matching using OpenCV\n",
    "\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "img = cv2.imread('dog.jpg',0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread('dog-head.jpg',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "    cv2.rectangle(img,top_left, bottom_right, 255, 5)\n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620bc881",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standard Hough line transform using OpenCV\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image and convert to grayscale\n",
    "img = cv2.imread('chess.png')\n",
    "img = cv2.resize(img, (640, 480))\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Apply Hough Line Transform\n",
    "lines = cv2.HoughLines(edges, rho=1, theta=np.pi/180, threshold=100)\n",
    "\n",
    "# Draw detected lines on original image\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 1000 * (-b))\n",
    "    y1 = int(y0 + 1000 * (a))\n",
    "    x2 = int(x0 - 1000 * (-b))\n",
    "    y2 = int(y0 - 1000 * (a))\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# Display result\n",
    "cv2.imshow('result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bd0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Probabilistic Hough transform using OpenCV\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image and convert to grayscale\n",
    "img = cv2.imread('chess.png')\n",
    "img = cv2.resize(img, (640, 480))\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Apply Probabilistic Hough Line Transform\n",
    "lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "\n",
    "# Draw detected lines on original image\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "# Display result\n",
    "cv2.imshow('result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed8c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### perform circle detection using the Hough Circle Transform in OpenCV:\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image and convert to grayscale\n",
    "img = cv2.imread('smarties.png')\n",
    "output=img.copy()\n",
    "\n",
    "# apply median blur\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.medianBlur(gray, 5)\n",
    "# Apply Hough Circle Transform\n",
    "circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                               param1=100, param2=30,\n",
    "                               minRadius=1, maxRadius=30)\n",
    "\n",
    "detected_circles = np.uint16(np.around(circles))\n",
    "# Draw detected circles on original image\n",
    "for (x, y, r) in detected_circles[0, :]:\n",
    "    cv2.circle(output, (x,y) , r, (0,255,0), 3)\n",
    "    cv2.circle(output, (x,y) , 2, (0,255,255), 3)\n",
    "\n",
    "\n",
    "# Display result\n",
    "cv2.imshow('output', output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Refer to the following code for displaying camera calibration using OpenCV.\n",
    "\n",
    "\n",
    "    \n",
    "# import required modules\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# Define the dimensions of the checkerboard pattern\n",
    "CHECKERBOARD = (6, 9)\n",
    "\n",
    "# Define the object points (3D coordinates of the checkerboard corners)\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Create arrays to store the object points and image points from all images\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "# Get a list of all calibration images\n",
    "images = glob.glob('checkerboard*.jpg')\n",
    "\n",
    "# Loop through each image and detect the checkerboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, None)\n",
    "\n",
    "    # If corners are detected, add object points and image points to their respective lists\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "# Calibrate the camera using the object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "# Displaying required output\n",
    "print(\"Camera matrix:\")\n",
    "print(mtx)\n",
    "\n",
    "print(\"\\n Distortion coefficient:\")\n",
    "print(dist)\n",
    "\n",
    "print(\"\\n Rotation Vectors:\")\n",
    "print(rvecs)\n",
    "\n",
    "print(\"\\n Translation Vectors:\")\n",
    "print(tvecs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857decb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738c1f17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24767af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f7060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821e950a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
